{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7085479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "import sys\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "#from keras.objectives import binary_crossentropy\n",
    "from keras.losses import BinaryCrossentropy\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Lambda, BatchNormalization, Dropout, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.regularizers import L1L2\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd66865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516cab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd37fcd",
   "metadata": {},
   "source": [
    "## Latent space of dim 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5992f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "latent_dim = 2\n",
    "dropout_rate = 0.3\n",
    "start_lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1551b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 12:05:41.096300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-20 12:05:41.097041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-20 12:05:41.097231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-20 12:05:41.097370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-20 12:05:42.024755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-20 12:05:42.025732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-20 12:05:42.025877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-20 12:05:42.025988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4153 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling layer \"model\" (type Model).\n\nUnimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n\nCall arguments received by layer \"model\" (type Model):\n  • inputs=tf.Tensor(shape=(500, 28, 28, 1), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (xent_loss \u001b[38;5;241m+\u001b[39m kl_loss)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m28\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models, vae_loss\n\u001b[0;32m---> 55\u001b[0m models, vae_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m vae \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn [7], line 44\u001b[0m, in \u001b[0;36mcreate_vae\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m decoded \u001b[38;5;241m=\u001b[39m Reshape((\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))(x)\n\u001b[1;32m     43\u001b[0m models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Model(z, decoded, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Model(input_img, models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m](\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVAE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvae_loss\u001b[39m(x, decoded):\n\u001b[1;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mreshape(x, shape\u001b[38;5;241m=\u001b[39m(batch_size, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:584\u001b[0m, in \u001b[0;36mModel.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_in_current_and_subclasses\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124;03m\"\"\"Calls the model on new inputs and returns the outputs as tensors.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m    In this case `call()` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnimplemented `tf.keras.Model.call()`: if you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintend to create a `Model` with the Functional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI, please provide `inputs` and `outputs` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments. Otherwise, subclass `Model` with an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverridden `call()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling layer \"model\" (type Model).\n\nUnimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n\nCall arguments received by layer \"model\" (type Model):\n  • inputs=tf.Tensor(shape=(500, 28, 28, 1), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "def create_vae():\n",
    "    models = {}\n",
    "\n",
    "    # Add Dropout and BatchNormalization\n",
    "    def apply_bn_and_dropout(x):\n",
    "        return Dropout(dropout_rate)(BatchNormalization()(x))\n",
    "\n",
    "    # Encoder\n",
    "    input_img = Input(batch_shape=(batch_size, 28, 28, 1))\n",
    "    x = Flatten()(input_img)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = apply_bn_and_dropout(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = apply_bn_and_dropout(x)\n",
    "\n",
    "    # Predict distribution params\n",
    "    # Predict variation log instead of st_dev\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "    # Sampling from Q with reparametrization\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.0)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    models[\"encoder\"]  = Model(input_img, l, 'Encoder') \n",
    "    models[\"z_meaner\"] = Model(input_img, z_mean, 'Enc_z_mean')\n",
    "    models[\"z_lvarer\"] = Model(input_img, z_log_var, 'Enc_z_log_var')\n",
    "\n",
    "    # Decoder\n",
    "    z = Input(shape=(latent_dim, ))\n",
    "    x = Dense(128)(z)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = apply_bn_and_dropout(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = apply_bn_and_dropout(x)\n",
    "    x = Dense(28*28, activation='sigmoid')(x)\n",
    "    decoded = Reshape((28, 28, 1))(x)\n",
    "\n",
    "    models[\"decoder\"] = Model(z, decoded, name='Decoder')\n",
    "    models[\"vae\"] = Model(input_img, models[\"decoder\"](models[\"encoder\"](input_img)), \\\n",
    "                          name=\"VAE\")\n",
    "\n",
    "    def vae_loss(x, decoded):\n",
    "        x = K.reshape(x, shape=(batch_size, 28*28))\n",
    "        decoded = K.reshape(decoded, shape=(batch_size, 28*28))\n",
    "        xent_loss = 28*28*BinaryCrossentropy(x, decoded)\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return (xent_loss + kl_loss)/2/28/28\n",
    "\n",
    "    return models, vae_loss\n",
    "\n",
    "models, vae_loss = create_vae()\n",
    "vae = models[\"vae\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
